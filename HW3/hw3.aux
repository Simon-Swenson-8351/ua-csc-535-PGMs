\relax 
\@writefile{toc}{\contentsline {section}{\numberline {1}Q1}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}a}{1}}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces The histograms of various numbers of samples from our sample generator overlayed with the actual PDF ($\mu = 0, \sigma = 1$). Top-left: 10 samples, top-right: 100 samples, bottom-left: 1000 sampes, bottom-right: 10000 samples}}{1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}b}{2}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Using our random sampler to generate samples for the beta distribution, comparing them to ground truth. ($\alpha = 2, \beta = 5$)}}{2}}
\@writefile{toc}{\contentsline {section}{\numberline {2}2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}a}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces The given prior, where $\alpha = 3, \beta = 3$. We can interpret this prior as having seen six coin flips, half of which were heads and half of which were tails. After only six coin-flips, we become relatively certain that it is a fair coin: The distribution reaches its peak at 0.5. With lower $\alpha , \beta $ values, the distribution might instead reach its maximum value at 0 and 1, indicating a loaded die with us not having enough information to determine which way the die is loaded. If, instead, our $\alpha , \beta $ values were higher and still equal, the peak at the center would become higher and steeper. This indicates our surity that the coin is fair. Though we are becoming more sure that the coin is fair, the current slope is still not very steep, and we need more coin tosses to verify this. }}{3}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces  If, instead of assuming continued fair coin tosses, as was mused upon above, we begin experimenting again and seeing only tails, the distribution quickly shifts away from the center. For each two tails we see with no heads, the peak becomes higher and is shifted further to the left (indicating a bias towards 0, what we interpret as tails) and its slope steeper. With such a heavily biased result, it is no wonder that the PDF changes so quickly. The chances of a fair coin landing tails even six times in a row is very low. }}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}b}{4}}
\@writefile{toc}{\contentsline {section}{\numberline {3}3}{5}}
\@writefile{toc}{\contentsline {section}{\numberline {4}4}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Using $ (A^T A)^{-1} A^T y $, we find the MLE for the coefficients of the polynomial for various degrees. Ground truth and randomly-generated dataset are present, as well.}}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces The error of the eight degrees of best-fit polynomials, plotted. You can see a sharp drop at the third degree. This is a good indicator that, in this case, the best degree to pick for the polynomial is three, since gains after that are not as substantial, and the polynomials of higher degree are likely overfitting the data. However, if we take error as our only metric for deciding how good a model is, the polynomial of degree seven wins. The \textbf  {oracle} provides a different picture from the random sampled data. Using the oracle data to compute error, the error reaches a minimum at exactly degree three. This illustrates the important difference between noisy, real-world data and ideal, oracle data.}}{7}}
\@writefile{toc}{\contentsline {section}{\numberline {5}5}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces \textbf  {Log likelihood} for best-fit polynomials of various degrees. Here, we see a clear spike at three, but the value continues steadily increasing. By log likelihood, the suggested best-fit polynomial is the one with the highest degree, seven. With \textbf  {AIC}, we consider the number of parameters in the model as a penalty. This penalty doing what we wanted by penalizing the higher-order models, but it is simply not doing enough. Eventually, the higher-order polynomials can overpower the metric. Thus, this metric still recommends a polynomial of degree seven. Again, \textbf  {BIC} is able to succeed in recommending the model with the expected degree, three. The BIC model is very similar to AIC, except that it factors in the number of data points as a penalty as well: If we need too many data points to get a good model, according to BIC, we might have a bad model. As $log(11) > 1$, this model provides a higher penalty than AIC, for our data set. Thus, it is finally able to recommend the desired degree of polynomial: three.}}{8}}
\@writefile{toc}{\contentsline {section}{\numberline {6}6}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces The familiar sudden change at degree three is present for both the training and the test data. However, the difference between the two is that, as the model fits the training data better and better, it actually overfits the data. Thus, while the training error always decreases, the test error starts increasing after three. The training error would recommend degree seven, but the test data, which I would say is more important for providing insight into predictive validity, recommends degree three.}}{9}}
\@writefile{toc}{\contentsline {section}{\numberline {7}7}{9}}
